{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8460b9a3-586f-4fc7-b851-34ee4fb78ad7"
    }
   },
   "source": [
    "# Detector de idiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4a761ccc-ac8f-4f0b-9fc1-145cd0f3f925"
    }
   },
   "source": [
    "Se va a diseñar un detector de idiomas utilizando recursos de **Machine Learning**. \n",
    "La idea principal es centrarlo en un problema de clasificación, con el que vamos a ayudarnos de una potente herramienta de ML para Python, **Scikit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "c718f844-42d9-4649-8dea-5f9e046069b9"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.externals import joblib\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2a95a74e-9f8e-49a3-88bb-c3bc4b9a820b"
    }
   },
   "source": [
    "Vamos a trabajar con corpus del Parlamento Europeo que se encuentran disponibles en el siguiente enlace:\n",
    "http://www.statmt.org/europarl/\n",
    "\n",
    "Abrimos los diferentes corpus.\n",
    "Aclaramos los idiomas:\n",
    "\n",
    "it = italiano  \n",
    "es = español  \n",
    "en = inglés  \n",
    "pt = portugués  \n",
    "fr = francés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "733e27e0-bc02-4a37-a623-0ce15687e6ea"
    }
   },
   "outputs": [],
   "source": [
    "it = open('corpus/italiano','r', encoding='utf8')\n",
    "es = open('corpus/espanol','r', encoding='utf8')\n",
    "en = open('corpus/ingles','r', encoding='utf8')\n",
    "fr = open('corpus/frances','r', encoding='utf8')\n",
    "pt = open('corpus/portugues','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "77def9c3-587f-4bd8-bee5-e85b7e9539ef"
    }
   },
   "outputs": [],
   "source": [
    "corpus_list = ['it', 'es', 'en', 'fr', 'pt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "726760fe-2a7e-4a2e-adb0-ac394199d00f"
    }
   },
   "source": [
    "Con la variable *size* le vamos a decir al programa la cantidad de frases con las que vamos a trabajar. Para que sea más fácil y todos los idiomas estén igualmente representados, procuraremos que *size* sea múltimo de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "8b8c4c73-1b85-483e-830e-b9071a08d580"
    }
   },
   "outputs": [],
   "source": [
    "size = 10000*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dcc1ce3a-14df-450b-94db-ea2b6acb713b"
    }
   },
   "source": [
    "A continuación vamos a crear el DataFrame que estará constituido simplemente con dos columnas, la primera será una frase y la segunda el idioma de dicha frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "6ca225d7-14dc-4ca4-95c8-71eb5c03c40f"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame creado en 0.0987 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "leng = []\n",
    "txt = []\n",
    "\n",
    "for j in corpus_list:\n",
    "    n = 0\n",
    "    for i in eval(j):\n",
    "        if n < (int(size/len(corpus_list))):\n",
    "            if len(i) >= 25:\n",
    "                n+=1\n",
    "                txt.append(i[:-1])\n",
    "                leng.append(str(j))\n",
    "        else:\n",
    "             break\n",
    "    eval(j).close()\n",
    "                \n",
    "df = pd.DataFrame()\n",
    "df['texto'] = txt\n",
    "df['idioma'] = leng\n",
    "\n",
    "print(\"DataFrame creado en %0.4f s\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver un pequeño resumen de nuestro DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "ebd731b4-ebbd-403c-8ed2-4a6cb7bba449"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49693</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Está encerrado o debate.</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           texto idioma\n",
       "count                      50000  50000\n",
       "unique                     49693      5\n",
       "top     Está encerrado o debate.     pt\n",
       "freq                          20  10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Reanudación del período de sesiones</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Declaro reanudado el período de sesiones del P...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Como todos han podido comprobar, el gran \"efec...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Sus Señorías han solicitado un debate sobre el...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>A la espera de que se produzca, de acuerdo con...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto idioma\n",
       "10000                Reanudación del período de sesiones     es\n",
       "10001  Declaro reanudado el período de sesiones del P...     es\n",
       "10002  Como todos han podido comprobar, el gran \"efec...     es\n",
       "10003  Sus Señorías han solicitado un debate sobre el...     es\n",
       "10004  A la espera de que se produzca, de acuerdo con...     es"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.idioma=='es'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40000</th>\n",
       "      <td>Declaro reaberta a sessão do Parlamento Europe...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40001</th>\n",
       "      <td>Como puderam constatar, o grande \"bug do ano 2...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>Os senhores manifestaram o desejo de se proced...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>Entretanto, gostaria - como também me foi pedi...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40004</th>\n",
       "      <td>Convido-os a levantarem-se para um minuto de s...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto idioma\n",
       "40000  Declaro reaberta a sessão do Parlamento Europe...     pt\n",
       "40001  Como puderam constatar, o grande \"bug do ano 2...     pt\n",
       "40002  Os senhores manifestaram o desejo de se proced...     pt\n",
       "40003  Entretanto, gostaria - como também me foi pedi...     pt\n",
       "40004  Convido-os a levantarem-se para um minuto de s...     pt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.idioma=='pt'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las frases repetidas, ya que no son interesantes para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='texto', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49693</td>\n",
       "      <td>49693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49693</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>De sus trabajos surgirán la estructura y los m...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>9948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto idioma\n",
       "count                                               49693  49693\n",
       "unique                                              49693      5\n",
       "top     De sus trabajos surgirán la estructura y los m...     fr\n",
       "freq                                                    1   9948"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos, a partir del DataFrame, nuestro conjunto de entrenamiento, train, y nuestro conjunto de validación, test.\n",
    "Para realizar esto utilizaremos la herramienta de Scikit-Learn *train_test_split* cuyo parámetro *test_size* nos va a indicar el tamaño del conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "ec81db57-acd1-4c13-aa1d-9f495ce4b8f6"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['texto'],\n",
    "    df['idioma'],\n",
    "    test_size=0.4,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "ec81db57-acd1-4c13-aa1d-9f495ce4b8f6"
    }
   },
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    test_size=0.5,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29815,), (9939,), (9939,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la funcion *feature_extraction.text.TfidfVectorizer* podremos separar la frase por palabras, lo que se conoce como *tokenizar*. El parámetro *analyzer='word'* nos indica que vamos a separar por palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "nbpresent": {
     "id": "c4b5f787-bf79-478e-a3f6-052a6d865de7"
    }
   },
   "outputs": [],
   "source": [
    "n_fts = 10000\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    analyzer = 'word',\n",
    "    ngram_range = (1, 1),\n",
    "    max_features = n_fts,\n",
    "    strip_accents = 'ascii',\n",
    "    max_df = 0.8,\n",
    "#     min_df = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos un Pipeline con el TfIdf y un algoritmo RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                             criterion='gini', max_depth=10, max_features='auto',\n",
    "                             max_leaf_nodes=None, max_samples=0.8,\n",
    "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                             min_samples_leaf=10, min_samples_split=5,\n",
    "                             min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                             n_jobs=-1, oob_score=True, random_state=0, verbose=0,\n",
    "                             warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=0.8,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=-1, oob_score=True, random_state=0, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.8, max_features=10000,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='ascii',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=10, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=0.8,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=10,\n",
       "                                        min_samples_split=5,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=-1,\n",
       "                                        oob_score=True, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('model', clf)\n",
    "])\n",
    "\n",
    "print('Entrenando modelo {}'.format(clf))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grado de acierto en los diferentes conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acierto en train:\n",
      "0.9844709039074292 \n",
      "\n",
      "Acierto en test:\n",
      "0.9847067109367139 \n",
      "\n",
      "Acierto en validación:\n",
      "0.9824932085722909 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Acierto en train:')\n",
    "preds_tr = model.predict(X_train)\n",
    "acc = accuracy_score(y_train, preds_tr)\n",
    "print(acc,'\\n')\n",
    "\n",
    "print('Acierto en test:')\n",
    "preds = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(acc,'\\n')\n",
    "\n",
    "print('Acierto en validación:')\n",
    "preds_val = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, preds_val)\n",
    "print(acc,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds, labels=corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar una matriz de confusión para hacer una primera comprobación tanto de los errores como de los aciertos cometidos por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "nbpresent": {
     "id": "f2b61e38-79d5-42cd-a77f-a7f75fe55a8e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>es</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>1944</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>6</td>\n",
       "      <td>1893</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      it    es    en    fr    pt\n",
       "it  1944     8     1     0    10\n",
       "es     6  1893     1     2    63\n",
       "en     1     0  1987     0    16\n",
       "fr     7    17     0  1963    18\n",
       "pt     0     1     1     0  2000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm,index=corpus_list,columns=corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ver, a través de la función *classification_report* la precisión del modelo por cada idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "nbpresent": {
     "id": "378a0dde-ac64-477c-9e60-1e6a45ea0d0d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          it       1.00      0.99      0.99      2004\n",
      "          es       0.99      0.96      0.97      1965\n",
      "          en       1.00      0.98      0.99      2005\n",
      "          fr       0.99      0.99      0.99      1963\n",
      "          pt       0.95      1.00      0.97      2002\n",
      "\n",
      "    accuracy                           0.98      9939\n",
      "   macro avg       0.99      0.98      0.98      9939\n",
      "weighted avg       0.99      0.98      0.98      9939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds,\n",
    "                                    target_names=corpus_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos guardar nuestras predicciones en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "nbpresent": {
     "id": "745d6474-4217-4941-9d75-a528a1d3e88a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13026</th>\n",
       "      <td>De conformidad con el orden del día, pasamos a...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>Vorrei chiedere alla Commissione se ha effettu...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>Questo per me è assolutamente inaccettabile, p...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41615</th>\n",
       "      <td>A Europol, a cooperação policial, não se encon...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30344</th>\n",
       "      <td>Et pour arriver à un élan plus rapide et effic...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29913</th>\n",
       "      <td>For despite these directives and frequent decl...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>Pensiamo che all'interno del concetto di multi...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12356</th>\n",
       "      <td>Pero en el contexto de dicha ayuda se debería ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33790</th>\n",
       "      <td>Cela parce que, premièrement, l' accent n' a p...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16284</th>\n",
       "      <td>De conformidad con el orden del día, se proced...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto idioma\n",
       "13026  De conformidad con el orden del día, pasamos a...     es\n",
       "1092   Vorrei chiedere alla Commissione se ha effettu...     it\n",
       "8148   Questo per me è assolutamente inaccettabile, p...     it\n",
       "41615  A Europol, a cooperação policial, não se encon...     pt\n",
       "30344  Et pour arriver à un élan plus rapide et effic...     fr\n",
       "29913  For despite these directives and frequent decl...     en\n",
       "4414   Pensiamo che all'interno del concetto di multi...     it\n",
       "12356  Pero en el contexto de dicha ayuda se debería ...     es\n",
       "33790  Cela parce que, premièrement, l' accent n' a p...     fr\n",
       "16284  De conformidad con el orden del día, se proced...     es"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['texto'] = X_test\n",
    "predictions['idioma'] = preds\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo entrenado para poder ejecutarlo en la aplicación Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/model.pkl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'models/model.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = joblib.load('models/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a crear una función sencilla, lo que sería el detector en sí, donde el parámetro de entrada será una frase y la salida será el idioma de dicha frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = ['it', 'es', 'en', 'fr', 'pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(model, x):\n",
    "    lenguage=model.predict([x])[0]\n",
    "    proba = model.predict_proba([x])\n",
    "    print(proba, max(proba[0]))\n",
    "    if lenguage == 'fr':\n",
    "        lenguage = 'francés'\n",
    "    elif lenguage == 'pt':\n",
    "        lenguage = 'portugués'\n",
    "    elif lenguage == 'it':\n",
    "        lenguage = 'italiano'\n",
    "    elif lenguage == 'en':\n",
    "        lenguage = 'inglés'\n",
    "    elif lenguage == 'es':\n",
    "        lenguage = 'español'\n",
    "        \n",
    "    print('El idioma de la frase es: '+lenguage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17061468 0.26047743 0.16121925 0.20523396 0.20245468]] 0.26047743392318173\n",
      "El idioma de la frase es: español\n"
     ]
    }
   ],
   "source": [
    "detection(model, 'hola, mi nombre es Errodringer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17061468 0.26047743 0.16121925 0.20523396 0.20245468]] 0.26047743392318173\n",
      "El idioma de la frase es: español\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'hola, mi nombre es Rodrigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16855631 0.21956045 0.16207203 0.216376   0.23343522]] 0.23343521575519052\n",
      "El idioma de la frase es: portugués\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'suscríbete al canal para seguir aprendiendo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31793718 0.16512693 0.15118934 0.17969129 0.18605527]] 0.3179371754801737\n",
      "El idioma de la frase es: inglés\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'subscribe and like to continue learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26144984 0.18072633 0.16378003 0.19316904 0.20087478]] 0.26144983503826436\n",
      "El idioma de la frase es: inglés\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'hello, my name is Rodrigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18605718 0.19777842 0.18004677 0.21374507 0.22237256]] 0.2223725568718269\n",
      "El idioma de la frase es: portugués\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'Alguem aqui fala espanhol?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16539579 0.17582645 0.16113572 0.29746113 0.20018091]] 0.2974611308082707\n",
      "El idioma de la frase es: italiano\n"
     ]
    }
   ],
   "source": [
    "detection(new_model, 'Piacere di conoscerla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
